<p align="center">
    <img width="280px" src="image/konglong/m4.png" >
</p>

# 大数据平台（4）从0到1搭建大数据平台之计算存储系统

## 一、传统的计算平台

我们都知道，没有大数据之前，我们计算平台基本是依赖数据库，大数据量的计算基本依赖Oracle数据库。Oracle很强大，支撑了很多年银行、电信业务数据的计算存储。Oracle多以集中式架构为主，最大特点就是将所有的数据都集中在一个数据库中，依靠大型高端设备来提供高处理能力和扩展性。集中式数据库的扩展性主要采用向上扩展的方式，通过增加CPU，内存，磁盘等方式提高处理能力。这种集中式数据库的架构，使得数据库成为了整个系统的瓶颈，已经越来越不适应海量数据对计算能力的巨大需求。同时传统数据库架构对高端设备的依赖，无疑将直接导致系统成本的大幅度增加，甚至可能会导致系统被主机和硬件厂商所“绑架”，不得不持续增加投入成本。

![图片](https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibQVysPsp4ztJoQHBMcrO2nrrzicIRtnicQchPFOkgS1IxhCFnzSQZxNnicsicOmCIHcrCHAgbIBKRicnA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

## 二、Hadoop的崛起

随着互联网行业的发展，特别是移动互联网的快速发展，传统数据库面临着海量数据的存储成本、有限的扩展能力等问题。新的计算框架MapReduce出现了，新的存储编码方式HDFS出现了，二者合起来，我们一般称之为Hadoop。



Hadoop很快凭借其高可靠性、高扩展性、成本低、高效计算等优势在各个领域得到了广泛应用。



![图片](https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibQVysPsp4ztJoQHBMcrO2nWOCLSHC9YJNyvbNB9sZZ5BHL4c59jGv5bF50SIeKTSic4oRUQL5OAEA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

## 三、Hive的应用

Hive最初是Facebook开源的，我们来看看Hive的特点：



- Hive是一个构建于Hadoop顶层的数据仓库工具，可以查询和管理PB级别的分布式数据。
- 支持类SQL语音。
- 可以看作为用户编程接口，本身不存储和处理数据
- 依赖HDFS作为存储



我们看到Hive支持类SQL语法，我们可以很容易的把传统关系型数据库建立的数据仓库任务迁移到Hadoop平台上。



Hive的架构：



![图片](https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibQVysPsp4ztJoQHBMcrO2nicOANhzJ0U62XJ0JrkYh0eBaaAS7j4SSG7n99CV11AZ7WQYBL6Gl44w/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



我们可以看到hive提供了多种连接方式：JDBC、ODBC、Thrift。



那么我们以前使用Oracle的存储过程怎么迁移到Hive中呢？用过Hive的同学可能都知道，Hive是没有想Oracle那样的游标循环呀，所以我们必须借助其他语言来配合hive一起完成数据仓库的ETL过程。比如这个项目：PyHive(https://github.com/dropbox/PyHive)



![图片](https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibQVysPsp4ztJoQHBMcrO2nDqvia3D75zFXHoriaCTmZ5kmhwDR7mfhr9JxIzM994YicxqEfOCx5iaDCA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



借助Python，我们可以很好的弥补Hive在复杂处理的一些缺陷，同时也能更好的开发ETL任务。



![图片](https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibQVysPsp4ztJoQHBMcrO2nONpLvqtxY6HJRwCJp4Jba90BJyasYABz843aPf6xh8UxGCbDuj2R7Q/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



所以，通过Hive我们就可以搭建起一套大数据计算平台。

## 四、Spark的应用

Hive在刚开始使用过程中很好用，对大数据量的处理确实比以前传统数据库要好，但是随着业务的增长，公司越来越多的数据工程师反馈查询慢，同时业务侧也纷纷提出，我们的数据能不能早点出，不要老是等到早上8点才刷新。我们需要更强大的计算引擎，Spark使用了十分之一的计算资源，获得了比Hadoop快3倍的速度，Spark为什么这么快呢？

我们来看看Spark的特点：

- 速度快，使用DGA（有向无环图）。
- 支持内存计算。
- 低延迟、高容错。

Spark提供了存计算，可以将计算结果存放到内存中，我们都知道MR是将数据存储在磁盘，对磁盘读写，势必会增加IO操作，计算时间过长。之前我也做过一个Hive和Spark的一个执行效率的对比，当时使用的是Spark1.6，数据是千万级别的表。



![图片](https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibQVysPsp4ztJoQHBMcrO2nW6sZyQQe9gv97J3qibfo4MVcj8EK9LiaRqHWmrPTEJfbI44QfIibnLXAw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



还是可以看出Spark比Hive快了很多，现在Spark2.0以后，会更快了。而且，Spark同样提供的有JDBC、ODBC 、Thrift连接方式。



![图片](https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibQVysPsp4ztJoQHBMcrO2nAlEHcCwqZY5ohZVBMUnQKbHZ4Okibibsst7b63AibwpiaMh7iae9LBeFGJA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



我们可以从Hive环境直接迁移到Spark环境，提高执行效率。



![图片](https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicibQVysPsp4ztJoQHBMcrO2nCVDalwfDC9F9Y1o9ZuW2NkjMZ4lOuBNLc4DYsKfUyWI9y5dZTwA61w/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

## 五、MPP的应用

用了Spark还是不够快，每次查询提交任务后，都得等着任务启动然后看着任务执行进度一直等着。

![图片](https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicicCBsSwsx38VBgntkf5QLbBoNmWpxB9dWeTjibdcHRz8piaxIPIUXibE7M4bYwBRkfoYvond2Ngs3FMA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

MPP（Massively Parallel Processing）是指多个处理器（或独立的计算机）并行处理一组协同计算。为了保证各节点的独立计算能力，MPP数据库通常采用ShareNothing架构。比较有代表性大家熟知的比如：GPDB、Vertica。

![图片](https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicicCBsSwsx38VBgntkf5QLbBu8N1s76dkggs7Yw7miaPNsVeRicfIaSibTsDn21icRermicSrWegcsJ44FA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

MPP具备以下特点：

- 低成本的硬件、和Hadoop一样，使用x86架构的PC就可以
- 数据存储采用不同的压缩算法，减少使用空间，提高IO性能
- 数据加载高效，并行加载、数据加载的速度取决于带宽
- 易扩展，容易对集群节点进行增减
- 列存储，很多MPP支持列存储架构，能够更高效的访问需要的数据
- 支持标准SQL，MPP比SparkSQL、HiveSQL对标准SQL支持的更好

从以上MPP的特点和上面我们介绍的Hadoop的特点，会发现MPP更适合数据自助分析、即席查询等场景、能够使数据人员快速获取数据结果。

## 六、搭建自己的计算平台

开源的计算引擎这么多、我们如何选择合适的计算引擎搭建平台呢？

下面分多个场景来和大家探讨下：

### 1、小公司、无大数据平台

真正的从无到有搭建大数据平台，开发人员较少。可以直接使用CDH搭建起来你的大数据平台，选用Hive作为数据仓库的计算引擎。为什么这样选择呢？很多小公司没有足够的资金支撑大数据平台的建设，那么就会选择相对来说的比较稳定的开源组件，Hive发展了很多年，和磁盘的交互MR计算架构中的任务很少会出错。Hive对SQL支持的很好，开发人员很容易上手，而且维护成本很低。

### 2、小公司、大数据平台升级

已经有过一段时间使用Hive作为计算引擎后，工程师们对大数据平台已经有一定的了解和知识积累，对Hadoop的运维能力也提升了，随着开发人员反馈Hive比较慢，领导也考虑升级平台，这时候就可以引入Spark了。上面我们也说了Spark是基于内存运算的，内存始终是没有磁盘稳定，Spark任务很多时候会因为资源设置不合理而报错。而SparkSQL和可以直接共享Hive的metestore，直接从Hive迁移到Spark上很自然，工作流很小。同时Spark还提供了Streaming功能，可以满足公司逐渐发展遇到的实时数据问题，再也不用担心以前hive没半小时执行一次任务，任务还偶尔出现执行不完的场景了。

### 3、大公司

很多传统行业的大公司一直依赖传统关系型数据库来处理数据，花了很多钱购置硬件和服务。现在要“降本增效”，必然会对IT部门下手。大公司有钱，就可以招聘到专业的工程师，他们有过建设大数据平台的经验，在计算选型上可以根据自己的技术栈选择合适的计算引擎。

另外，可以买一些MPP数据库的服务，比如GreenPlum商业版、Vertica。商业版的很稳定，几乎不会碰到棘手的问题，平时只管使用就行了，大大提高的运维、开发效率。对比下来会发现比以前使用传统的关系型数据库省了不少钱。



![图片](https://mmbiz.qpic.cn/mmbiz_png/z2DApiaibzMicicCBsSwsx38VBgntkf5QLbBVRjZBZcSeK3LhNnwmGjhs93IS0oxgAcKBibkCPlAZ0dlFspiaXsnicaOA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

## 七、总结

基于多个计算引擎搭建大数据平台是目前的现状，针对不同的企业和团队选择适合自己的，同一个公司不同的业务也可以选择不同的计算引擎。不考虑商业方案，就要根据自己的技术掌握情况，选择自己精通的并且适合业务的。考虑商业方案的可以选择商业的MPP，给开发和业务人员提供更好的环境和体验。